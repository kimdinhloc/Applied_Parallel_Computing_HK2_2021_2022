{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LTSS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimdinhloc/Applied_Parallel_Programming_HK2_2021_2022/blob/main/LTSS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL2K_1AZwutM",
        "outputId": "6f858f99-39d0-42d6-aa67-f14054e9b931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-08 15:52:12--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  40.9MB/s    in 6.2s    \n",
            "\n",
            "2022-05-08 15:52:19 (38.4 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n",
            "--2022-05-08 15:52:19--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg’\n",
            "\n",
            "yolov3.cfg          100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-08 15:52:19 (76.5 MB/s) - ‘yolov3.cfg’ saved [8342/8342]\n",
            "\n",
            "--2022-05-08 15:52:19--  https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘coco.names’\n",
            "\n",
            "coco.names          100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-08 15:52:19 (41.2 MB/s) - ‘coco.names’ saved [625/625]\n",
            "\n",
            "--2022-05-08 15:52:19--  https://raw.githubusercontent.com/kimdinhloc/Applied_Parallel_Programming_HK2_2021_2022/main/Illustrated%20image/Dog.JPG\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15302 (15K) [image/jpeg]\n",
            "Saving to: ‘Dog.JPG’\n",
            "\n",
            "Dog.JPG             100%[===================>]  14.94K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-05-08 15:52:19 (29.1 MB/s) - ‘Dog.JPG’ saved [15302/15302]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
        "!wget https://raw.githubusercontent.com/kimdinhloc/Applied_Parallel_Programming_HK2_2021_2022/main/Illustrated%20image/Dog.JPG"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import segmentation\n",
        "from numba import jit, prange, cuda\n",
        "import time\n",
        "import math\n",
        "import sys"
      ],
      "metadata": {
        "id": "YoL3dzvDw0Ww"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(Image):\n",
        "    ''' \n",
        "    Load YOLOv3 model and detect objects \n",
        "    return:\n",
        "    outs: list of detected objects\n",
        "    '''\n",
        "    try:\n",
        "        configuration = \"yolov3.cfg\"\n",
        "        weights = \"yolov3.weights\"\n",
        "        classesFile = \"coco.names\"\n",
        "        classes = None\n",
        "    \n",
        "        with open(classesFile, 'rt') as f:\n",
        "            classes = f.read().rstrip('\\n').split('\\n')\n",
        "\n",
        "        net = cv2.dnn.readNetFromDarknet(configuration, weights)\n",
        "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
        "    except:\n",
        "        print(\"Error: Cannot load model\")\n",
        "        sys.exit()\n",
        "    try:\n",
        "        inputWidth,inputHeight=608,608\n",
        "        blob = cv2.dnn.blobFromImage(Image, 1 / 255, (inputWidth, inputHeight), [0, 0, 0], 1, crop=False)\n",
        "        net.setInput(blob)\n",
        "        layersNames = net.getLayerNames()\n",
        "        outs = net.forward([layersNames[index[0] - 1] for index in net.getUnconnectedOutLayers()])\n",
        "    except:\n",
        "        print(\"Error: Cannot detect objects\")\n",
        "        sys.exit()\n",
        "    return outs\n",
        "\n",
        "def postprocess(frameHeight, frameWidth, outs,confThreshold=0.0):\n",
        "    boxes = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            classId = np.argmax(scores)\n",
        "            confidence = scores[classId]\n",
        "            if confidence > confThreshold:\n",
        "                center_x = int(detection[0] * frameWidth)\n",
        "                center_y = int(detection[1] * frameHeight)\n",
        "                width = int(detection[2] * frameWidth)\n",
        "                height = int(detection[3] * frameHeight)\n",
        "                left = int(center_x - width / 2)\n",
        "                top = int(center_y - height / 2)\n",
        "                boxes.append([left, top, width, height])\n",
        "    return boxes\n",
        "#convert to CIE-LAB\n",
        "def BRG2CIELAB(inPixels):\n",
        "    '''\n",
        "    Convert BRG to CIELAB\n",
        "\n",
        "    praram:\n",
        "    ----\n",
        "    inPixels: numpy array of shape (B,G,R)\n",
        "\n",
        "    output:\n",
        "    ----\n",
        "    outPixels: numpy array of shape (L,a,b)\n",
        "    '''\n",
        "\n",
        "    #convert BGR to XYZ\n",
        "    #https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#cvtcolor\n",
        "    #BRG -> CIE XYZ.Rec 709 with D65 white point\n",
        "    index = 0\n",
        "    for value in inPixels:\n",
        "        if value/255 > 0.04045:\n",
        "            inPixels[index] = (((value/255 + 0.055) / 1.055) ** 2.4)*100\n",
        "        else:\n",
        "            inPixels[index] = value/255 * 100/12.92\n",
        "        index += 1\n",
        "\n",
        "    XYZ_colvolution = np.matrix([[0.412453, 0.357580, 0.180423],\n",
        "              [0.212671, 0.715160, 0.072169],\n",
        "              [0.019334, 0.119193, 0.950227]], dtype=np.float32)\n",
        "    BGR = np.matrix([inPixels[2], inPixels[1], inPixels[0]]).T #.T is transpose to 3x1 matrix\n",
        "    XYZ = np.dot(XYZ_colvolution, BGR)\n",
        "    # Observer= 2°, Illuminant= D65\n",
        "    XYZ[0]=XYZ[0]/95.047\n",
        "    XYZ[1]=XYZ[1]/100.000\n",
        "    XYZ[2]=XYZ[2]/108.883\n",
        "\n",
        "    #convert XYZ to CIE-LAB\n",
        "    #https://en.wikipedia.org/wiki/Lab_color_space\n",
        "\n",
        "    index=0\n",
        "    for value in XYZ:\n",
        "        if value>0.008856:\n",
        "            XYZ[index]=np.power(value,1/3)\n",
        "        else:\n",
        "            XYZ[index]=(7.787*value)+(16/116)\n",
        "        index+=1\n",
        "\n",
        "    L=float(116*XYZ[1]-16)\n",
        "    a=float(500*(XYZ[0]-XYZ[1]))\n",
        "    b=float(200*(XYZ[1]-XYZ[2]))\n",
        "    return [round(L,4),round(a,4),round(b,4)]\n",
        "def convert2CIELAB(inImg):\n",
        "    '''\n",
        "    Convert RGB image to CIELAB\n",
        "    params:\n",
        "    inImg - image input\n",
        "    return:\n",
        "    outImg - image output\n",
        "    '''    \n",
        "    #initialize the output image\n",
        "    outImg=np.zeros(inImg.shape,dtype=np.float32)\n",
        "\n",
        "    #loop over the image, and convert the RGB values to CIELAB each pixel\n",
        "    for h in range(inImg.shape[0]):\n",
        "        for w in range(inImg.shape[1]):\n",
        "            outImg[h,w,:]=BRG2CIELAB(inImg[h,w,:])\n",
        "            \n",
        "    return outImg\n",
        "def find_local_minimum(inImg,center):\n",
        "    minGradient = 1\n",
        "    localMinium = center\n",
        "    for i in range(center[0] - 1, center[0] + 2):\n",
        "        for j in range(center[1] - 1, center[1] + 2):\n",
        "            cluster1 = inImg[j+1, i]\n",
        "            cluster2 = inImg[j, i+1]\n",
        "            cluster3 = inImg[j, i]\n",
        "            C=np.sqrt(pow(float(cluster1[0] - cluster3[0]),2)) +  np.sqrt(pow(float(cluster2[0] - cluster3[0]),2))\n",
        "            if C < minGradient:\n",
        "                minGradient = abs(cluster1[0] - cluster3[0]) + abs(cluster2[0] - cluster3[0])\n",
        "                localMinium = [i, j]\n",
        "    return localMinium\n",
        "def calculate_centers(inImg,S):\n",
        "    '''\n",
        "    Calculate the centers of the segments\n",
        "    params:\n",
        "    inImg - image input\n",
        "    S - number of segments\n",
        "    return:\n",
        "    centers - list of centers\n",
        "    '''\n",
        "    centers = []\n",
        "    for w in range(S, inImg.shape[1] - int(S/2), S):\n",
        "        for h in range(S, inImg.shape[0] - int(S/2), S):\n",
        "            nc = find_local_minimum(inImg,center=(w, h))\n",
        "            color = inImg[nc[1], nc[0]] #height x width\n",
        "            center = [color[0], color[1], color[2], nc[0], nc[1]] # l, a, b, height, width\n",
        "            centers.append(center)\n",
        "    return centers"
      ],
      "metadata": {
        "id": "TXG3yftexCJp"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}